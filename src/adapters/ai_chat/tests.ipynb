{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8135443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory (before): f:\\Dev\\interview-service\\interview-service\\src\\adapters\\ai_chat\n",
      "Project root: F:\\Dev\\interview-service\\interview-service\n",
      "Working directory (after): F:\\Dev\\interview-service\\interview-service\n",
      "pyproject.toml exists: True\n",
      "src/ exists: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Get the current working directory (where notebook is executed from)\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "# Start from current directory and search upward for project root\n",
    "# Project root should contain pyproject.toml (not in src/)\n",
    "project_root = current_dir\n",
    "max_levels = 10  # Safety limit\n",
    "\n",
    "for _ in range(max_levels):\n",
    "    \n",
    "    # Check if this directory contains pyproject.toml\n",
    "    if (project_root / \"pyproject.toml\").exists():\n",
    "        # Verify it's the actual project root (not a subdirectory)\n",
    "        # Project root should have pyproject.toml and src/ directory\n",
    "        if (project_root / \"src\").exists() and (project_root / \"pyproject.toml\").exists():\n",
    "            break\n",
    "    if project_root == project_root.parent:\n",
    "        # Reached filesystem root\n",
    "        break\n",
    "    project_root = project_root.parent\n",
    "else:\n",
    "    # Fallback: go up 3 levels from current directory if we're in src/adapters/ai_chat/\n",
    "    if \"src\" in str(current_dir) and \"adapters\" in str(current_dir):\n",
    "        project_root = current_dir.parent.parent.parent\n",
    "\n",
    "# Add project root to Python path (must be absolute path)\n",
    "project_root = project_root.resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Change working directory to project root\n",
    "os.chdir(project_root)\n",
    "\n",
    "print(f\"Current directory (before): {current_dir}\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Working directory (after): {os.getcwd()}\")\n",
    "print(f\"pyproject.toml exists: {(project_root / 'pyproject.toml').exists()}\")\n",
    "print(f\"src/ exists: {(project_root / 'src').exists()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "589c501e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<openai.OpenAI object at 0x000001FA18C12A50>\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from src.adapters.ai_chat.ai_chat import AIChat\n",
    "from src.domain.vacancy.vacancy import VacancyInfo\n",
    "from src.domain.message.message import Message, RoleEnum, TypeEnum\n",
    "from src.domain.task.task import Task, TaskType\n",
    "import asyncio\n",
    "import dotenv   \n",
    "import os\n",
    "from config import MODEL_NAME, TOKEN_LIMIT\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# Вариант с доменом без порта (HTTPS):\n",
    "BASE_URL = \"https://llm.t1v.scibox.tech/v1\"\n",
    "# Альтернатива с IP:порт\n",
    "# BASE_URL = \"http://45.145.191.148:4000/v1\"\n",
    "\n",
    "client = OpenAI(api_key=API_KEY, base_url=BASE_URL)\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc9ab766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwen3-32b-awq 25000\n"
     ]
    }
   ],
   "source": [
    "print(MODEL_NAME, TOKEN_LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55277701",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# resp = client.chat.completions.create(\n",
    "#     model=\"qwen3-32b-awq\",\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"Ты дружелюбный помощник\"},\n",
    "#         {\"role\": \"user\", \"content\": \"Расскажи анекдот\"},\n",
    "#     ],\n",
    "#     temperature=0.7,\n",
    "#     top_p=0.9,    max_tokens=20000,\n",
    "# )\n",
    "\n",
    "# print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18e518d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with client.chat.completions.stream(\n",
    "#     model=\"qwen3-32b-awq\",\n",
    "#     messages=[{\"role\": \"user\", \"content\": \"Сделай краткое резюме книги Война и мир\"}],\n",
    "#     max_tokens=20000,\n",
    "# ) as stream:\n",
    "#     for event in stream:\n",
    "#         if event.type == \"chunk\":\n",
    "#             delta = getattr(event.chunk.choices[0].delta, \"content\", None)\n",
    "#             if delta:\n",
    "#                 print(delta, end=\"\", flush=True)\n",
    "#         elif event.type == \"message.completed\":\n",
    "#             print()  # newlinefrom openai import OpenAI\n",
    "# import dotenv   \n",
    "# import os\n",
    "\n",
    "# dotenv.load_dotenv()\n",
    "\n",
    "# API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# # Вариант с доменом без порта (HTTPS):\n",
    "# BASE_URL = \"https://llm.t1v.scibox.tech/v1\"\n",
    "# # Альтернатива с IP:порт\n",
    "# # BASE_URL = \"http://45.145.191.148:4000/v1\"\n",
    "\n",
    "# client = OpenAI(api_key=API_KEY, base_url=BASE_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf020b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ai_utils.misc import get_chat_completion_stream\n",
    "\n",
    "# stream = get_chat_completion_stream(client, \"qwen3-32b-awq\", [{\"role\": \"user\", \"content\": \"Сделай задачу для собеседования AI разработчика на Python и тесты для нее\"}], 20000)\n",
    "\n",
    "# for chunk in stream:\n",
    "#     print(chunk, end=\"\", flush=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "932b134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from src.domain.vacancy.vacancy import VacancyInfo\n",
    "from src.domain.message.message import Message, RoleEnum, TypeEnum\n",
    "from src.domain.task.task import Task, TaskType\n",
    "from datetime import timedelta\n",
    "\n",
    "# Create example vacancy info\n",
    "vacancy_info = VacancyInfo(\n",
    "    profession=\"Python разработчик / Data Scientist\",\n",
    "    position=\"Junior Python Developer\",\n",
    "    requirements=\"Pandas, Numpy, Tensorflow, PyTorch, SQLAlchemy\",\n",
    "    questions=\"\",\n",
    "    tasks=None,\n",
    "    task_ides=None,\n",
    "    interview_plan=\"\",  # Will be generated by create_chat\n",
    "    duration=timedelta(minutes=30)\n",
    ")\n",
    "\n",
    "# Create example chat history\n",
    "chat_history = [\n",
    "    # Message(\n",
    "    #     role=RoleEnum.USER,\n",
    "    #     type=TypeEnum.QUESTION,\n",
    "    #     content=\"Привет! Можете рассказать о вакансии?\"\n",
    "    # ),\n",
    "    # Message(\n",
    "    #     role=RoleEnum.AI,\n",
    "    #     type=TypeEnum.ANSWER,\n",
    "    #     content=\"Конечно! Мы ищем Senior Python Developer с опытом работы с FastAPI.\"\n",
    "    # )\n",
    "]\n",
    "\n",
    "# Create example task\n",
    "task = Task(\n",
    "    type=TaskType.CODE,\n",
    "    language=\"Python\",\n",
    "    description=\"Реализуйте функцию для валидации email адреса\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee1d46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing create_chat...\n",
      "=== Updated Vacancy Info ===\n",
      "Profession: Python разработчик / Data Scientist\n",
      "Position: Junior Python Developer\n",
      "\n",
      "Interview Plan (first 300 chars):\n",
      "INTERNAL INTERVIEW PLAN – DO NOT SHARE WITH CANDIDATE  \n",
      "\n",
      "1. **Warm-up (10-15 min)**  \n",
      "   - [theory] *Explain the key differences between Pandas DataFrames and NumPy arrays. When would you use one over the other?*  \n",
      "   - [theory] *What is the role of SQLAlchemy in Python applications? How does it differ from raw SQL?*  \n",
      "\n",
      "2. **Core Coding Tasks (40-50 min)**  \n",
      "   - **Task 1: Data Manipulation [coding]**  \n",
      "     *Write a script that loads a CSV file into a Pandas DataFrame, filters rows where a column 'value' exceeds 100, and calculates the mean of another column 'score' grouped by a categorical column 'category'.*  \n",
      "   - **Task 2: Machine Learning Basics [coding]**  \n",
      "     *Using either TensorFlow or PyTorch, create a simple neural network with one hidden layer to classify the Iris dataset (assume preloaded data). Output the model summary.*  \n",
      "   - **Task 3: ORM with SQLAlchemy [coding]**  \n",
      "     *Define a SQLAlchemy model class for a \"User\" table with fields: id (primary key), name (string), email (string, unique). Write code to add a new user and query all users with names starting with 'A'.*  \n",
      "\n",
      "3. **Follow-ups & Optimization (15-20 min)**  \n",
      "   - [theory] *How would you handle missing values in the DataFrame from Task 1? Discuss at least two strategies.*  \n",
      "   - [theory] *Compare the use cases of TensorFlow vs. PyTorch for a junior developer. Which would you choose for a simple project and why?*  \n",
      "   - [coding] *Modify the SQLAlchemy code from Task 3 to include a relationship with a new \"Post\" table (id, content, user_id as foreign key). Output the number of posts per user.*  \n",
      "\n",
      "4. **Wrap-up (5-10 min)**  \n",
      "   - [theory] *Explain how you would deploy a Python script using NumPy/Pandas to production. What tools or frameworks would you consider?*  \n",
      "   - Optional: Ask candidate to highlight their proudest technical achievement related to Python/data work.  \n",
      "\n",
      "Note: Tasks are ordered from foundational (data handling) to applied (ML/ORM). Emphasize code readability and use of best practices in all coding tasks....\n",
      "\n",
      "Full Interview Plan Length: 2033 characters\n",
      "\n",
      "==================================================\n",
      "\n",
      "Testing generate_welcome_message...\n",
      "\n",
      "=== Welcome Message (streaming) ===\n",
      "\n",
      "Thinking...\n",
      "Finished thinking.\n",
      "\n",
      "\n",
      "Добро пожаловать! В ходе интервью вы будете решать технические задачи в встроенной среде разработки. Общее время ограничено, поэтому старайтесь быть эффективными. Я помогу разобраться с поставленными вопросами, но не буду писать готовые решения — ваша цель показать, как вы подходите к задачам и пишете код.  \n",
      "\n",
      "**Важно:**  \n",
      "- Не используйте внешние инструменты (LLM, IDE вне платформы).  \n",
      "- Не копируйте код из интернета — всё должно быть написано вручную в эмуляторе.  \n",
      "- Не пытайтесь обойти правила: чат будет проверен модератором, и любые попытки обмана приведут к дисквалификации.  \n",
      "\n",
      "Начнём с первой задачи.\n",
      "\n",
      "=== Full Welcome Message ===\n",
      "Thinking...\n",
      "Finished thinking.\n",
      "\n",
      "\n",
      "Добро пожаловать! В ходе интервью вы будете решать технические задачи в встроенной среде разработки. Общее время ограничено, поэтому старайтесь быть эффективными. Я помогу разобраться с поставленными вопросами, но не буду писать готовые решения — ваша цель показать, как вы подходите к задачам и пишете код.  \n",
      "\n",
      "**Важно:**  \n",
      "- Не используйте внешние инструменты (LLM, IDE вне платформы).  \n",
      "- Не копируйте код из интернета — всё должно быть написано вручную в эмуляторе.  \n",
      "- Не пытайтесь обойти правила: чат будет проверен модератором, и любые попытки обмана приведут к дисквалификации.  \n",
      "\n",
      "Начнём с первой задачи.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test create_chat function\n",
    "async def test_create_chat():\n",
    "    ai_chat = AIChat()\n",
    "    \n",
    "    # create_chat returns updated VacancyInfo with interview_plan\n",
    "    updated_vacancy = await ai_chat.create_chat(vacancy_info, chat_history)\n",
    "    \n",
    "    print(\"=== Updated Vacancy Info ===\")\n",
    "    print(f\"Profession: {updated_vacancy.profession}\")\n",
    "    print(f\"Position: {updated_vacancy.position}\")\n",
    "    print(f\"\\nInterview Plan (first 300 chars):\")\n",
    "    print(updated_vacancy.interview_plan + \"...\" if len(updated_vacancy.interview_plan) > 300 else updated_vacancy.interview_plan)\n",
    "    print(f\"\\nFull Interview Plan Length: {len(updated_vacancy.interview_plan)} characters\")\n",
    "\n",
    "# Test generate_welcome_message function\n",
    "async def test_generate_welcome_message():\n",
    "    ai_chat = AIChat()\n",
    "    \n",
    "    # First create chat to get updated vacancy with interview_plan\n",
    "    updated_vacancy = await ai_chat.create_chat(vacancy_info, chat_history)\n",
    "    \n",
    "    print(\"\\n=== Welcome Message (streaming) ===\\n\")\n",
    "    welcome_chunks = []\n",
    "    \n",
    "    # ❌ before:\n",
    "    # async for chunk in ai_chat.generate_welcome_message(updated_vacancy, chat_history):\n",
    "\n",
    "    # ✅ after:\n",
    "    stream = await ai_chat.generate_welcome_message(updated_vacancy, chat_history)\n",
    "    async for chunk in stream:\n",
    "        welcome_chunks.append(chunk)\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "    \n",
    "    print(\"\\n\\n=== Full Welcome Message ===\")\n",
    "    full_welcome = \"\".join(welcome_chunks)\n",
    "    print(full_welcome)\n",
    "\n",
    "# Run the async functions\n",
    "print(\"Testing create_chat...\")\n",
    "await test_create_chat()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Testing generate_welcome_message...\")\n",
    "await test_generate_welcome_message()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00a2453e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Response to Task (streaming) ===\n",
      "\n",
      "Thinking...\n",
      "Finished thinking.\n",
      "\n",
      "\n",
      "Пожалуйста, начните с объяснения, как вы планируете валидировать email. Например:  \n",
      "- Какие критерии вы будете проверять (например, наличие символа @, корректность домена)?  \n",
      "- Будете ли вы использовать регулярные выражения или другой подход?  \n",
      "- Какие граничные случаи вы считаете важными для проверки (например, email без точки в домене, с цифрами и т.д.)?  \n",
      "\n",
      "После этого вы можете приступить к написанию кода.\n",
      "\n",
      "=== Full Response ===\n",
      "Thinking...\n",
      "Finished thinking.\n",
      "\n",
      "\n",
      "Пожалуйста, начните с объяснения, как вы планируете валидировать email. Например:  \n",
      "- Какие критерии вы будете проверять (например, наличие символа @, корректность домена)?  \n",
      "- Будете ли вы использовать регулярные выражения или другой подход?  \n",
      "- Какие граничные случаи вы считаете важными для проверки (например, email без точки в домене, с цифрами и т.д.)?  \n",
      "\n",
      "После этого вы можете приступить к написанию кода.\n"
     ]
    }
   ],
   "source": [
    "# Test create_response function (for reference)\n",
    "async def test_create_response():\n",
    "    ai_chat = AIChat()\n",
    "    \n",
    "    # First create chat to get updated vacancy\n",
    "    updated_vacancy = await ai_chat.create_chat(vacancy_info, chat_history)\n",
    "    \n",
    "    # Then create response with task\n",
    "    print(\"\\n=== Response to Task (streaming) ===\\n\")\n",
    "    response_chunks = []\n",
    "    stream = await ai_chat.create_response(updated_vacancy, chat_history, task)\n",
    "    async for chunk in stream:\n",
    "        response_chunks.append(chunk)\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "    \n",
    "    print(\"\\n\\n=== Full Response ===\")\n",
    "    full_response = \"\".join(response_chunks)\n",
    "    print(full_response)\n",
    "\n",
    "# Run the async function\n",
    "await test_create_response()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fee9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERNAL INTERVIEW PLAN ONLY – DO NOT DISCLOSE TO CANDIDATE  \n",
      "\n",
      "1. **Warm-up (5-7 min)**  \n",
      "   - [theory] Explain the key differences between Pandas DataFrames and NumPy arrays. When would you use one over the other?  \n",
      "\n",
      "2. **Theoretical Questions (10-12 min)**  \n",
      "   - [theory] How does SQLAlchemy’s ORM abstract database interactions? Provide an example of a Python class mapping to a database table.  \n",
      "   - [theory] Compare TensorFlow and PyTorch in terms of use cases and dynamic vs. static computation graphs.  \n",
      "\n",
      "3. **Core Coding Tasks (25-30 min)**  \n",
      "   - [coding] Write a NumPy script to normalize a 2D array (row-wise) and handle missing values (replace with column mean).  \n",
      "   - [coding] Given a Pandas DataFrame with missing timestamps and categorical features, write code to:  \n",
      "     - Fill missing timestamps with the previous valid value.  \n",
      "     - One-hot encode categorical columns.  \n",
      "   - [coding] Implement a simple neural network in PyTorch for binary classification (1 hidden layer, sigmoid activation).  \n",
      "\n",
      "4. **Advanced Integration Task (15-20 min)**  \n",
      "   - [coding] Using SQLAlchemy, define a model for a \"User\" table with fields: id (primary key), name (string), email (unique), and created_at (datetime). Write a query to fetch all users created in the last 7 days.  \n",
      "\n",
      "5. **Wrap-up & Follow-ups (5-7 min)**  \n",
      "   - [theory] Discuss potential bottlenecks when using Pandas for large datasets and how to optimize performance.  \n",
      "   - [optional] If time allows, ask the candidate to explain and debug a provided snippet with a common NumPy/Pandas gotcha (e.g., chained assignments or view vs. copy issues).\n",
      "\n",
      "=== Streaming Task Description ===\n",
      "\n",
      "Thinking...\n",
      "Finished thinking.\n",
      "\n",
      "\n",
      "[theory] Explain the key differences between Pandas DataFrames and NumPy arrays. When would you use one over the other?\n",
      "\n",
      "=== Full Task Description ===\n",
      "Thinking...\n",
      "Finished thinking.\n",
      "\n",
      "\n",
      "[theory] Explain the key differences between Pandas DataFrames and NumPy arrays. When would you use one over the other?\n"
     ]
    }
   ],
   "source": [
    "# Test stream_task function\n",
    "async def test_stream_task():\n",
    "    ai_chat = AIChat()\n",
    "    \n",
    "    # First create chat to get updated vacancy with interview_plan\n",
    "    updated_vacancy = await ai_chat.create_chat(vacancy_info, chat_history)\n",
    "    print(updated_vacancy.interview_plan)\n",
    "    # Then stream the task\n",
    "    print(\"\\n=== Streaming Task Description ===\\n\")\n",
    "    task_chunks = []\n",
    "    \n",
    "    stream = await ai_chat.stream_task(updated_vacancy, chat_history)\n",
    "    async for chunk in stream:\n",
    "        task_chunks.append(chunk)\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "    \n",
    "    print(\"\\n\\n=== Full Task Description ===\")\n",
    "    full_task = \"\".join(task_chunks)\n",
    "    print(full_task)\n",
    "\n",
    "# Run the async function\n",
    "await test_stream_task()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd906fe",
   "metadata": {},
   "source": [
    "#TODO: Перевести на русский это в промпте"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
