{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8135443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory (before): f:\\Dev\\interview-service\\interview-service\\src\\adapters\\ai_chat\n",
      "Project root: F:\\Dev\\interview-service\\interview-service\n",
      "Working directory (after): F:\\Dev\\interview-service\\interview-service\n",
      "pyproject.toml exists: True\n",
      "src/ exists: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Get the current working directory (where notebook is executed from)\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "# Start from current directory and search upward for project root\n",
    "# Project root should contain pyproject.toml (not in src/)\n",
    "project_root = current_dir\n",
    "max_levels = 10  # Safety limit\n",
    "\n",
    "for _ in range(max_levels):\n",
    "    \n",
    "    # Check if this directory contains pyproject.toml\n",
    "    if (project_root / \"pyproject.toml\").exists():\n",
    "        # Verify it's the actual project root (not a subdirectory)\n",
    "        # Project root should have pyproject.toml and src/ directory\n",
    "        if (project_root / \"src\").exists() and (project_root / \"pyproject.toml\").exists():\n",
    "            break\n",
    "    if project_root == project_root.parent:\n",
    "        # Reached filesystem root\n",
    "        break\n",
    "    project_root = project_root.parent\n",
    "else:\n",
    "    # Fallback: go up 3 levels from current directory if we're in src/adapters/ai_chat/\n",
    "    if \"src\" in str(current_dir) and \"adapters\" in str(current_dir):\n",
    "        project_root = current_dir.parent.parent.parent\n",
    "\n",
    "# Add project root to Python path (must be absolute path)\n",
    "project_root = project_root.resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Change working directory to project root\n",
    "os.chdir(project_root)\n",
    "\n",
    "print(f\"Current directory (before): {current_dir}\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Working directory (after): {os.getcwd()}\")\n",
    "print(f\"pyproject.toml exists: {(project_root / 'pyproject.toml').exists()}\")\n",
    "print(f\"src/ exists: {(project_root / 'src').exists()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "589c501e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<openai.OpenAI object at 0x000001A502910830>\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from src.adapters.ai_chat.ai_chat import AIChat\n",
    "from src.domain.vacancy.vacancy import VacancyInfo\n",
    "from src.domain.message.message import Message, RoleEnum, TypeEnum\n",
    "from src.domain.task.task import Task, TaskType\n",
    "import asyncio\n",
    "import dotenv   \n",
    "import os\n",
    "from config import MODEL_NAME, TOKEN_LIMIT\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# Вариант с доменом без порта (HTTPS):\n",
    "BASE_URL = \"https://llm.t1v.scibox.tech/v1\"\n",
    "# Альтернатива с IP:порт\n",
    "# BASE_URL = \"http://45.145.191.148:4000/v1\"\n",
    "\n",
    "client = OpenAI(api_key=API_KEY, base_url=BASE_URL)\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc9ab766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwen3-32b-awq 25000\n"
     ]
    }
   ],
   "source": [
    "print(MODEL_NAME, TOKEN_LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "651050e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_interview_plan = \"\"\"INTERNAL INTERVIEW PLAN ONLY - DO NOT SHARE WITH CANDIDATES  \n",
    "\n",
    "1. **Warm-up Question (5-7 min)**  \n",
    "   - [theory] *Explain the primary use cases for Pandas DataFrames vs. NumPy ndarrays. When would you choose one over the other?*  \n",
    "\n",
    "2. **Theoretical Questions (10-12 min)**  \n",
    "   - [theory] *What is the purpose of SQLAlchemy's ORM layer? How does it simplify database interactions compared to raw SQL?*  \n",
    "   - [theory] *Compare TensorFlow and PyTorch. In what scenarios is each framework typically preferred?*  \n",
    "\n",
    "3. **Core Coding Tasks (30-35 min)**  \n",
    "   - **Task 1** [coding] *Write Pandas code to load a CSV file, filter rows where column 'A' > 10, and calculate the mean of column 'B'.*  \n",
    "   - **Task 2** [coding] *Create a NumPy array of shape (3,3) filled with random values. Compute eigenvalues and perform matrix inversion.*  \n",
    "   - **Task 3** [coding] *Build a simple neural network (1 hidden layer) using PyTorch/TensorFlow to classify the Iris dataset (skeleton code provided). Compile and explain the model.*  \n",
    "\n",
    "4. **Follow-up & Debugging (10-12 min)**  \n",
    "   - [theory] *Explain how you would optimize the Pandas code for large datasets.*  \n",
    "   - [coding] *Debug a provided SQLAlchemy ORM query that fails to join two tables correctly.*  \n",
    "\n",
    "5. **Wrap-up (3-5 min)**  \n",
    "   - [theory] *What are the key challenges when integrating NumPy/TensorFlow for GPU-accelerated computations?*  \n",
    "\n",
    "---  \n",
    "**Timing Notes**: Adjust based on candidate performance. Prioritize depth in core libraries (Pandas, NumPy) over framework specifics.\"\"\"\n",
    "\n",
    "ai_message_content_1 = \"\"\"Здравствуйте! Добро пожаловать на техническое интервью.  \n",
    "В ходе интервью вы будете решать задачи на Python (Pandas, Numpy, PyTorch и др.) в встроенной среде. Время ограничено, поэтому работайте аккуратно и оперативно.  \n",
    "Вы можете задавать уточняющие вопросы по условию задач, но не ожидайте, что я напишу решение за вас — я помогу направить вас в правильное русло. Мы также обсудим ваш подход и код.  \n",
    "**Важно:** не используйте внешние инструменты (LLM, поисковики), не копируйте код извне — всё должно быть введено вручную. Попытки обойти правила приведут к дезавалидации интервью.  \n",
    "Чат будет проверен после завершения. Начнём с первой задачи — готовы?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "932b134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from src.domain.vacancy.vacancy import VacancyInfo\n",
    "from src.domain.message.message import Message, RoleEnum, TypeEnum\n",
    "from src.domain.task.task import Task, TaskType\n",
    "from datetime import timedelta\n",
    "\n",
    "# Create example vacancy info\n",
    "vacancy_info = VacancyInfo(\n",
    "    profession=\"Python разработчик / Data Scientist\",\n",
    "    position=\"Junior Python Developer\",\n",
    "    requirements=\"Pandas, Numpy, Tensorflow, PyTorch, SQLAlchemy\",\n",
    "    questions=\"\",\n",
    "    tasks=None,\n",
    "    task_ides=None,\n",
    "    interview_plan=test_interview_plan,  # Will be generated by create_chat\n",
    "    duration=timedelta(minutes=30)\n",
    ")\n",
    "\n",
    "# Create example chat history\n",
    "chat_history = [\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.RESPONSE,\n",
    "        content=ai_message_content_1\n",
    "    ),\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.QUESTION,\n",
    "        content=\"Поясните основные случаи использования Pandas DataFrames и NumPy ndarrays. В каких ситуациях вы выберете один инструмент вместо другого?\"\n",
    "    ),\n",
    "    Message(\n",
    "        role=RoleEnum.USER,\n",
    "        type=TypeEnum.OTHER,\n",
    "        content=\"А... можете пояснить вопрос? Напомните, что такое ndarray?\"\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "ai_chat = AIChat()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0a4e209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing create_response...\n",
      "=== Classification ===\n",
      "User message type:      question\n",
      "Assistant message type: hint\n",
      "\n",
      "=== AI response (streaming) ===\n",
      "\n",
      "  \n",
      "NumPy ndarray (N-мерный массив) — это основной тип данных в NumPy для работы с числовыми данными, оптимизированный для высокой производительности. Он представляет собой однородную структуру (все элементы одного типа) и поддерживает векторизованные операции. Pandas DataFrame — это структура, похожая на таблицу в Excel, с поддержкой разнотиповых колонок, индексации и операций, характерных для работы с данными (фильтрация, группировка и т.д.).  \n",
      "\n",
      "Попробуйте сформулировать, в каких сценариях использование одного из этих инструментов предпочтительнее. Например: когда нужно выполнять математические вычисления над массивами данных — NumPy, а когда работать с табличными данными, содержащими разнородные типы — Pandas.\n",
      "\n",
      "=== Final AI message ===\n",
      "Role:    ai\n",
      "Type:    hint\n",
      "Content:   \n",
      "NumPy ndarray (N-мерный массив) — это основной тип данных в NumPy для работы с числовыми данными, оптимизированный для высокой производительности. Он представляет собой однородную структуру (все элементы одного типа) и поддерживает векторизованные операции. Pandas DataFrame — это структура, похожая на таблицу в Excel, с поддержкой разнотиповых колонок, индексации и операций, характерных для работы с данными (фильтрация, группировка и т.д.).  \n",
      "\n",
      "Попробуйте сформулировать, в каких сценариях использование одного из этих инструментов предпочтительнее. Например: когда нужно выполнять математические вычисления над массивами данных — NumPy, а когда работать с табличными данными, содержащими разнородные типы — Pandas.\n"
     ]
    }
   ],
   "source": [
    "# Test create_response function\n",
    "async def test_create_response():\n",
    "    ai_chat = AIChat()\n",
    "    \n",
    "    # Example task for this interview turn\n",
    "    task = Task(\n",
    "        type=TaskType.THEORY,\n",
    "        language=\"Python\",\n",
    "        description=\"Поясните основные случаи использования Pandas DataFrames и NumPy ndarrays. В каких ситуациях вы выберете один инструмент вместо другого?\"\n",
    "    )\n",
    "\n",
    "    stream, user_msg, ai_msg = await ai_chat.create_response(\n",
    "        vacancy_info=vacancy_info,\n",
    "        chat_history=chat_history,\n",
    "        task=task,\n",
    "    )\n",
    "\n",
    "    # Fill user message content from the last USER message in history\n",
    "    last_user_msg = next((m for m in reversed(chat_history) if m.role == RoleEnum.USER), None)\n",
    "    if last_user_msg:\n",
    "        user_msg.content = last_user_msg.content\n",
    "\n",
    "    print(\"=== Classification ===\")\n",
    "    print(f\"User message type:      {user_msg.type}\")\n",
    "    print(f\"Assistant message type: {ai_msg.type}\")\n",
    "\n",
    "    print(\"\\n=== AI response (streaming) ===\\n\")\n",
    "    chunks: list[str] = []\n",
    "    async for chunk in stream:\n",
    "        chunks.append(chunk)\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "\n",
    "    ai_msg.content = \"\".join(chunks)\n",
    "\n",
    "    print(\"\\n\\n=== Final AI message ===\")\n",
    "    print(f\"Role:    {ai_msg.role}\")\n",
    "    print(f\"Type:    {ai_msg.type}\")\n",
    "    print(f\"Content: {ai_msg.content}\")\n",
    "\n",
    "\n",
    "print(\"Testing create_response...\")\n",
    "await test_create_response()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4964646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dc572ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stream' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mstream\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'stream' is not defined"
     ]
    }
   ],
   "source": [
    "stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ee1d46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing create_chat...\n",
      "=== Updated Vacancy Info ===\n",
      "Profession: Python разработчик / Data Scientist\n",
      "Position: Junior Python Developer\n",
      "\n",
      "Interview Plan (first 300 chars):\n",
      "INTERNAL INTERVIEW PLAN ONLY (DO NOT SHARE WITH CANDIDATE)\n",
      "\n",
      "1. **Warm-up (5-10 min)**  \n",
      "   - [theory] Explain how to handle missing data in Pandas DataFrames. Demonstrate .dropna() vs .fillna() with example scenarios.  \n",
      "\n",
      "2. **Core Libraries Assessment (30-40 min)**  \n",
      "   - [coding] Numpy task: Write a function to normalize a 2D array (row-wise) and handle division by zero.  \n",
      "   - [theory] Compare Tensorflow and PyTorch: When would you choose one over the other? Discuss dynamic vs static computation graphs.  \n",
      "\n",
      "3. **ML Frameworks Practical (20-30 min)**  \n",
      "   - [coding] PyTorch task: Implement a single-layer neural network for binary classification (define model, loss function, and optimizer).  \n",
      "\n",
      "4. **Database Integration (15-20 min)**  \n",
      "   - [theory] Explain SQLAlchemy's ORM approach. How does it differ from raw SQL? Provide an example of a mapped class for a \"users\" table.  \n",
      "\n",
      "5. **Wrap-up (5 min)**  \n",
      "   - Open chat discussion: Ask candidate to explain their most complex Python project and challenges with data manipulation/ML pipeline.  \n",
      "\n",
      "Note: Prioritize coding tasks for Numpy/PyTorch, ensure theoretical questions validate understanding of core concepts. Adjust timing based on candidate pace....\n",
      "\n",
      "Full Interview Plan Length: 1209 characters\n",
      "\n",
      "==================================================\n",
      "\n",
      "Testing generate_welcome_message...\n",
      "\n",
      "=== Welcome Message (streaming) ===\n",
      "\n",
      "Thinking...\n",
      "Finished thinking.\n",
      "\n",
      "\n",
      "Здравствуйте! Добро пожаловать на техническое интервью.  \n",
      "В ходе интервью вы будете решать задачи на Python (Pandas, Numpy, PyTorch и др.) в встроенной среде. Время ограничено, поэтому работайте аккуратно и оперативно.  \n",
      "Вы можете задавать уточняющие вопросы по условию задач, но не ожидайте, что я напишу решение за вас — я помогу направить вас в правильное русло. Мы также обсудим ваш подход и код.  \n",
      "**Важно:** не используйте внешние инструменты (LLM, поисковики), не копируйте код извне — всё должно быть введено вручную. Попытки обойти правила приведут к дезавалидации интервью.  \n",
      "Чат будет проверен после завершения. Начнём с первой задачи — готовы?\n",
      "\n",
      "=== Full Welcome Message ===\n",
      "Thinking...\n",
      "Finished thinking.\n",
      "\n",
      "\n",
      "Здравствуйте! Добро пожаловать на техническое интервью.  \n",
      "В ходе интервью вы будете решать задачи на Python (Pandas, Numpy, PyTorch и др.) в встроенной среде. Время ограничено, поэтому работайте аккуратно и оперативно.  \n",
      "Вы можете задавать уточняющие вопросы по условию задач, но не ожидайте, что я напишу решение за вас — я помогу направить вас в правильное русло. Мы также обсудим ваш подход и код.  \n",
      "**Важно:** не используйте внешние инструменты (LLM, поисковики), не копируйте код извне — всё должно быть введено вручную. Попытки обойти правила приведут к дезавалидации интервью.  \n",
      "Чат будет проверен после завершения. Начнём с первой задачи — готовы?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test create_chat function\n",
    "async def test_create_chat():\n",
    "    ai_chat = AIChat()\n",
    "    \n",
    "    # create_chat returns updated VacancyInfo with interview_plan\n",
    "    updated_vacancy = await ai_chat.create_chat(vacancy_info, chat_history)\n",
    "    \n",
    "    print(\"=== Updated Vacancy Info ===\")\n",
    "    print(f\"Profession: {updated_vacancy.profession}\")\n",
    "    print(f\"Position: {updated_vacancy.position}\")\n",
    "    print(f\"\\nInterview Plan (first 300 chars):\")\n",
    "    print(updated_vacancy.interview_plan + \"...\" if len(updated_vacancy.interview_plan) > 300 else updated_vacancy.interview_plan)\n",
    "    print(f\"\\nFull Interview Plan Length: {len(updated_vacancy.interview_plan)} characters\")\n",
    "\n",
    "# Test generate_welcome_message function\n",
    "async def test_generate_welcome_message():\n",
    "    ai_chat = AIChat()\n",
    "    \n",
    "    # First create chat to get updated vacancy with interview_plan\n",
    "    updated_vacancy = await ai_chat.create_chat(vacancy_info, chat_history)\n",
    "    \n",
    "    print(\"\\n=== Welcome Message (streaming) ===\\n\")\n",
    "    welcome_chunks = []\n",
    "    \n",
    "    # ❌ before:\n",
    "    # async for chunk in ai_chat.generate_welcome_message(updated_vacancy, chat_history):\n",
    "\n",
    "    # ✅ after:\n",
    "    stream = await ai_chat.generate_welcome_message(updated_vacancy, chat_history)\n",
    "    async for chunk in stream:\n",
    "        welcome_chunks.append(chunk)\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "    \n",
    "    print(\"\\n\\n=== Full Welcome Message ===\")\n",
    "    full_welcome = \"\".join(welcome_chunks)\n",
    "    print(full_welcome)\n",
    "\n",
    "# Run the async functions\n",
    "print(\"Testing create_chat...\")\n",
    "await test_create_chat()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Testing generate_welcome_message...\")\n",
    "await test_generate_welcome_message()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a2453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test create_response function (for reference)\n",
    "async def test_create_response():\n",
    "    ai_chat = AIChat()\n",
    "    \n",
    "    # First create chat to get updated vacancy\n",
    "    updated_vacancy = await ai_chat.create_chat(vacancy_info, chat_history)\n",
    "    \n",
    "    # Then create response with task\n",
    "    print(\"\\n=== Response to Task (streaming) ===\\n\")\n",
    "    response_chunks = []\n",
    "    stream = await ai_chat.create_response(updated_vacancy, chat_history, task)\n",
    "    async for chunk in stream:\n",
    "        response_chunks.append(chunk)\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "    \n",
    "    print(\"\\n\\n=== Full Response ===\")\n",
    "    full_response = \"\".join(response_chunks)\n",
    "    print(full_response)\n",
    "\n",
    "# Run the async function\n",
    "await test_create_response()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dfee1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fee9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERNAL INTERVIEW PLAN ONLY - DO NOT SHARE WITH CANDIDATES  \n",
      "\n",
      "1. **Warm-up Question (5-7 min)**  \n",
      "   - [theory] *Explain the primary use cases for Pandas DataFrames vs. NumPy ndarrays. When would you choose one over the other?*  \n",
      "\n",
      "2. **Theoretical Questions (10-12 min)**  \n",
      "   - [theory] *What is the purpose of SQLAlchemy's ORM layer? How does it simplify database interactions compared to raw SQL?*  \n",
      "   - [theory] *Compare TensorFlow and PyTorch. In what scenarios is each framework typically preferred?*  \n",
      "\n",
      "3. **Core Coding Tasks (30-35 min)**  \n",
      "   - **Task 1** [coding] *Write Pandas code to load a CSV file, filter rows where column 'A' > 10, and calculate the mean of column 'B'.*  \n",
      "   - **Task 2** [coding] *Create a NumPy array of shape (3,3) filled with random values. Compute eigenvalues and perform matrix inversion.*  \n",
      "   - **Task 3** [coding] *Build a simple neural network (1 hidden layer) using PyTorch/TensorFlow to classify the Iris dataset (skeleton code provided). Compile and explain the model.*  \n",
      "\n",
      "4. **Follow-up & Debugging (10-12 min)**  \n",
      "   - [theory] *Explain how you would optimize the Pandas code for large datasets.*  \n",
      "   - [coding] *Debug a provided SQLAlchemy ORM query that fails to join two tables correctly.*  \n",
      "\n",
      "5. **Wrap-up (3-5 min)**  \n",
      "   - [theory] *What are the key challenges when integrating NumPy/TensorFlow for GPU-accelerated computations?*  \n",
      "\n",
      "---  \n",
      "**Timing Notes**: Adjust based on candidate performance. Prioritize depth in core libraries (Pandas, NumPy) over framework specifics.\n",
      "\n",
      "=== Streaming Task Description ===\n",
      "\n",
      "Thinking...\n",
      "Finished thinking.\n",
      "\n",
      "\n",
      "[theory]  \n",
      "Поясните основные случаи использования Pandas DataFrames и NumPy ndarrays. В каких ситуациях вы выберете один инструмент вместо другого?\n",
      "\n",
      "=== Full Task Description ===\n",
      "Thinking...\n",
      "Finished thinking.\n",
      "\n",
      "\n",
      "[theory]  \n",
      "Поясните основные случаи использования Pandas DataFrames и NumPy ndarrays. В каких ситуациях вы выберете один инструмент вместо другого?\n"
     ]
    }
   ],
   "source": [
    "# Test stream_task function\n",
    "async def test_stream_task():\n",
    "    ai_chat = AIChat()\n",
    "    \n",
    "    # First create chat to get updated vacancy with interview_plan\n",
    "    # updated_vacancy = await ai_chat.create_chat(vacancy_info, chat_history)\n",
    "    vacancy_info.interview_plan = test_interview_plan\n",
    "    updated_vacancy = vacancy_info\n",
    "    print(updated_vacancy.interview_plan)\n",
    "    # Then stream the task\n",
    "    print(\"\\n=== Streaming Task Description ===\\n\")\n",
    "    task_chunks = []\n",
    "    \n",
    "    stream = await ai_chat.stream_task(updated_vacancy, chat_history)\n",
    "    async for chunk in stream:\n",
    "        task_chunks.append(chunk)\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "    \n",
    "    print(\"\\n\\n=== Full Task Description ===\")\n",
    "    full_task = \"\".join(task_chunks)\n",
    "    print(full_task)\n",
    "\n",
    "# Run the async function\n",
    "await test_stream_task()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
