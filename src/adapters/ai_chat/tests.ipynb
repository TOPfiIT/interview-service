{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8135443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory (before): f:\\Dev\\interview-service\\interview-service\\src\\adapters\\ai_chat\n",
      "Project root: F:\\Dev\\interview-service\\interview-service\n",
      "Working directory (after): F:\\Dev\\interview-service\\interview-service\n",
      "pyproject.toml exists: True\n",
      "src/ exists: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Get the current working directory (where notebook is executed from)\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "# Start from current directory and search upward for project root\n",
    "# Project root should contain pyproject.toml (not in src/)\n",
    "project_root = current_dir\n",
    "max_levels = 10  # Safety limit\n",
    "\n",
    "for _ in range(max_levels):\n",
    "    \n",
    "    # Check if this directory contains pyproject.toml\n",
    "    if (project_root / \"pyproject.toml\").exists():\n",
    "        # Verify it's the actual project root (not a subdirectory)\n",
    "        # Project root should have pyproject.toml and src/ directory\n",
    "        if (project_root / \"src\").exists() and (project_root / \"pyproject.toml\").exists():\n",
    "            break\n",
    "    if project_root == project_root.parent:\n",
    "        # Reached filesystem root\n",
    "        break\n",
    "    project_root = project_root.parent\n",
    "else:\n",
    "    # Fallback: go up 3 levels from current directory if we're in src/adapters/ai_chat/\n",
    "    if \"src\" in str(current_dir) and \"adapters\" in str(current_dir):\n",
    "        project_root = current_dir.parent.parent.parent\n",
    "\n",
    "# Add project root to Python path (must be absolute path)\n",
    "project_root = project_root.resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Change working directory to project root\n",
    "os.chdir(project_root)\n",
    "\n",
    "print(f\"Current directory (before): {current_dir}\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Working directory (after): {os.getcwd()}\")\n",
    "print(f\"pyproject.toml exists: {(project_root / 'pyproject.toml').exists()}\")\n",
    "print(f\"src/ exists: {(project_root / 'src').exists()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "589c501e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<openai.OpenAI object at 0x000001A152718AD0>\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from src.adapters.ai_chat.ai_chat import AIChat\n",
    "from src.domain.vacancy.vacancy import VacancyInfo\n",
    "from src.domain.message.message import Message, RoleEnum, TypeEnum\n",
    "from src.domain.task.task import Task, TaskType\n",
    "from src.domain.metrics.metrics import MetricsBlock1, MetricsBlock2, MetricsBlock3\n",
    "import asyncio\n",
    "import dotenv   \n",
    "import os\n",
    "from config import MODEL_NAME, TOKEN_LIMIT\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# Вариант с доменом без порта (HTTPS):\n",
    "BASE_URL = \"https://llm.t1v.scibox.tech/v1\"\n",
    "# Альтернатива с IP:порт\n",
    "# BASE_URL = \"http://45.145.191.148:4000/v1\"\n",
    "\n",
    "client = OpenAI(api_key=API_KEY, base_url=BASE_URL)\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc9ab766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwen3-32b-awq 25000\n"
     ]
    }
   ],
   "source": [
    "print(MODEL_NAME, TOKEN_LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "651050e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_interview_plan = \"\"\"INTERNAL INTERVIEW PLAN ONLY - DO NOT SHARE WITH CANDIDATES  \n",
    "\n",
    "1. **Warm-up Question (5-7 min)**  \n",
    "   - [theory] *Explain the primary use cases for Pandas DataFrames vs. NumPy ndarrays. When would you choose one over the other?*  \n",
    "\n",
    "2. **Theoretical Questions (10-12 min)**  \n",
    "   - [theory] *What is the purpose of SQLAlchemy's ORM layer? How does it simplify database interactions compared to raw SQL?*  \n",
    "   - [theory] *Compare TensorFlow and PyTorch. In what scenarios is each framework typically preferred?*  \n",
    "\n",
    "3. **Core Coding Tasks (30-35 min)**  \n",
    "   - **Task 1** [coding] *Write Pandas code to load a CSV file, filter rows where column 'A' > 10, and calculate the mean of column 'B'.*  \n",
    "   - **Task 2** [coding] *Create a NumPy array of shape (3,3) filled with random values. Compute eigenvalues and perform matrix inversion.*  \n",
    "   - **Task 3** [coding] *Build a simple neural network (1 hidden layer) using PyTorch/TensorFlow to classify the Iris dataset (skeleton code provided). Compile and explain the model.*  \n",
    "\n",
    "4. **Follow-up & Debugging (10-12 min)**  \n",
    "   - [theory] *Explain how you would optimize the Pandas code for large datasets.*  \n",
    "   - [coding] *Debug a provided SQLAlchemy ORM query that fails to join two tables correctly.*  \n",
    "\n",
    "5. **Wrap-up (3-5 min)**  \n",
    "   - [theory] *What are the key challenges when integrating NumPy/TensorFlow for GPU-accelerated computations?*  \n",
    "\n",
    "---  \n",
    "**Timing Notes**: Adjust based on candidate performance. Prioritize depth in core libraries (Pandas, NumPy) over framework specifics.\"\"\"\n",
    "\n",
    "ai_message_content_1 = \"\"\"Здравствуйте! Добро пожаловать на техническое интервью.  \n",
    "В ходе интервью вы будете решать задачи на Python (Pandas, Numpy, PyTorch и др.) в встроенной среде. Время ограничено, поэтому работайте аккуратно и оперативно.  \n",
    "Вы можете задавать уточняющие вопросы по условию задач, но не ожидайте, что я напишу решение за вас — я помогу направить вас в правильное русло. Мы также обсудим ваш подход и код.  \n",
    "**Важно:** не используйте внешние инструменты (LLM, поисковики), не копируйте код извне — всё должно быть введено вручную. Попытки обойти правила приведут к дезавалидации интервью.  \n",
    "Чат будет проверен после завершения. Начнём с первой задачи — готовы?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "932b134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from src.domain.vacancy.vacancy import VacancyInfo\n",
    "from src.domain.message.message import Message, RoleEnum, TypeEnum\n",
    "from src.domain.task.task import Task, TaskType\n",
    "from datetime import timedelta\n",
    "\n",
    "# Create example vacancy info\n",
    "vacancy_info = VacancyInfo(\n",
    "    profession=\"Python разработчик / Data Scientist\",\n",
    "    position=\"Junior Python Developer\",\n",
    "    requirements=\"Pandas, Numpy, Tensorflow, PyTorch, SQLAlchemy\",\n",
    "    questions=\"\",\n",
    "    tasks=None,\n",
    "    task_ides=None,\n",
    "    interview_plan=test_interview_plan,  # Will be generated by create_chat\n",
    "    duration=timedelta(minutes=30)\n",
    ")\n",
    "\n",
    "# Create example chat history\n",
    "chat_history = [\n",
    "    # Message(\n",
    "    #     role=RoleEnum.AI,\n",
    "    #     type=TypeEnum.RESPONSE,\n",
    "    #     content=ai_message_content_1\n",
    "    # ),\n",
    "    # Message(\n",
    "    #     role=RoleEnum.AI,\n",
    "    #     type=TypeEnum.QUESTION,\n",
    "    #     content=\"Поясните основные случаи использования Pandas DataFrames и NumPy ndarrays. В каких ситуациях вы выберете один инструмент вместо другого?\"\n",
    "    # ),\n",
    "    # Message(\n",
    "    #     role=RoleEnum.USER,\n",
    "    #     type=TypeEnum.OTHER,\n",
    "    #     content=\"А... можете пояснить вопрос? Напомните, что такое ndarray?\"\n",
    "    # )\n",
    "]\n",
    "\n",
    "\n",
    "ai_chat = AIChat()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7265965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from src.domain.vacancy.vacancy import VacancyInfo\n",
    "from src.domain.message.message import Message, RoleEnum, TypeEnum\n",
    "\n",
    "# --- INTERNAL PLAN (no libraries, ~30 minutes) ---\n",
    "\n",
    "test_interview_plan = \"\"\"INTERNAL INTERVIEW PLAN ONLY - DO NOT SHARE WITH CANDIDATES  \n",
    "\n",
    "1. **Разогрев (3–5 мин)**  \n",
    "   - [theory] *Что такое список в Python и чем он отличается от кортежа? Приведите пару примеров.*  \n",
    "\n",
    "2. **Базовая теория (5–7 мин)**  \n",
    "   - [theory] *Чем список отличается от строки с точки зрения изменяемости и типичных операций?*  \n",
    "   - [theory] *Что такое функция в Python и зачем нужны аргументы по умолчанию?*  \n",
    "\n",
    "3. **Основные задачки по коду (15–18 мин)**  \n",
    "   - **Task 1** [coding] *Написать функцию `sum_to_n(n)`, которая для целого n возвращает сумму чисел от 1 до n. Без сторонних библиотек.*  \n",
    "   - **Task 2** [coding] *Реализовать классический FizzBuzz: вывести числа от 1 до 100, заменяя кратные 3 на \"Fizz\", кратные 5 на \"Buzz\", кратные и 3 и 5 на \"FizzBuzz\". Только стандартный Python.*  \n",
    "\n",
    "4. **Дебаг и доработка (3–4 мин)**  \n",
    "   - [coding] *Попросить кандидата учесть граничные случаи в sum_to_n (n <= 0, некорректный ввод) и обсудить их решение.*  \n",
    "\n",
    "5. **Финал (2–3 мин)**  \n",
    "   - [theory] *Короткий вопрос про читаемость кода, выбор имён переменных и простые практики оформления.*  \n",
    "\n",
    "---  \n",
    "**Timing Notes**: План рассчитан примерно на 30 минут. При необходимости сокращаем теорию и не расширяем FizzBuzz за пределы базового варианта.\n",
    "\"\"\"\n",
    "\n",
    "# --- WELCOME MESSAGE (AI) ---\n",
    "\n",
    "ai_message_content_1 = \"\"\"Здравствуйте! Добро пожаловать на техническое интервью на позицию Junior Python Developer.  \n",
    "В этом интервью мы будем работать только с чистым Python — без сторонних библиотек. Вам предстоят несколько коротких теоретических вопросов и 1–2 небольшие задачки по коду.  \n",
    "Вы можете задавать уточняющие вопросы по условию, но я не буду писать решения за вас — моя задача оценить ваши навыки и помочь наводящими подсказками.  \n",
    "Пожалуйста, не используйте внешние инструменты (LLM, поисковики) и не копируйте заранее подготовленный код. Всё решение должно быть введено вами вручную.  \n",
    "Если всё понятно, давайте начнём с небольшого разогрева.\n",
    "\"\"\"\n",
    "\n",
    "# --- VACANCY INFO MOCK ---\n",
    "\n",
    "vacancy_info = VacancyInfo(\n",
    "    profession=\"Python разработчик\",\n",
    "    position=\"Junior Python Developer\",\n",
    "    requirements=\"Базовый Python, типы данных, условия, циклы, функции. Без внешних библиотек.\",\n",
    "    questions=\"Базовая теория по спискам, строкам, функциям, простые задачки на циклы и условия.\",\n",
    "    tasks=None,\n",
    "    task_ides=None,\n",
    "    interview_plan=test_interview_plan,\n",
    "    duration=timedelta(minutes=30),\n",
    ")\n",
    "\n",
    "# --- CHAT HISTORY MOCK (FULL 30-MIN INTERVIEW) ---\n",
    "\n",
    "chat_history = [\n",
    "    # 1. Приветствие и правила\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.RESPONSE,\n",
    "        content=ai_message_content_1,\n",
    "    ),\n",
    "\n",
    "    # 2. Разогрев – теоретический вопрос\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.QUESTION,\n",
    "        content=\"Для начала небольшой вопрос: что такое список в Python и чем он отличается от кортежа? Приведите пару простых примеров.\",\n",
    "    ),\n",
    "    Message(\n",
    "        role=RoleEnum.USER,\n",
    "        type=TypeEnum.ANSWER,\n",
    "        content=(\n",
    "            \"Список — это такой контейнер, где можно хранить разные значения. \"\n",
    "            \"Кортеж, кажется, примерно то же самое, только в круглых скобках. \"\n",
    "            \"Честно говоря, не помню точно, в чём ещё разница, кроме скобок.\"\n",
    "        ),\n",
    "    ),\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.HINT,\n",
    "        content=(\n",
    "            \"В целом верно, что и список, и кортеж хранят коллекцию значений. \"\n",
    "            \"Ключевая разница — изменяемость: список можно изменять (добавлять, удалять, менять элементы), \"\n",
    "            \"а кортеж — нет. Это важно, например, при передаче данных, которые не должны меняться.\"\n",
    "        ),\n",
    "    ),\n",
    "\n",
    "    # 3. Теория – ещё один вопрос, кандидат слабоват\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.QUESTION,\n",
    "        content=\"А чем список отличается от строки с точки зрения операций и изменяемости?\",\n",
    "    ),\n",
    "    Message(\n",
    "        role=RoleEnum.USER,\n",
    "        type=TypeEnum.ANSWER,\n",
    "        content=(\n",
    "            \"Строка — это тоже как массив символов. Кажется, её тоже можно менять по индексу, \"\n",
    "            \"но я так почти не делал. В основном я к строкам просто что-то дописывал через '+'.\"\n",
    "        ),\n",
    "    ),\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.CHECK_SOLUTION,\n",
    "        content=(\n",
    "            \"Тут есть неточность: строки в Python **неизменяемы**, как и кортежи. \"\n",
    "            \"Когда вы 'дописываете' к строке, на самом деле создаётся новая строка. \"\n",
    "            \"Список же можно менять по индексу и модифицировать на месте. Это важно для понимания работы памяти и скорости.\"\n",
    "        ),\n",
    "    ),\n",
    "\n",
    "    # 4. Переход к коду – Task 1\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.TASK,\n",
    "        content=(\n",
    "            \"[coding][python]\\n\"\n",
    "            \"Задание 1. Напишите функцию `sum_to_n(n)`, которая возвращает сумму чисел от 1 до n включительно. \"\n",
    "            \"Считайте, что n — целое число. Сторонние библиотеки использовать нельзя.\"\n",
    "        ),\n",
    "    ),\n",
    "    Message(\n",
    "        role=RoleEnum.USER,\n",
    "        type=TypeEnum.SOLUTION,\n",
    "        content=(\n",
    "            \"Я сделал так: \\n\"\n",
    "            \"def sum_to_n(n):\\n\"\n",
    "            \"    s = 0\\n\"\n",
    "            \"    for i in range(1, n+1):\\n\"\n",
    "            \"        s += i\\n\"\n",
    "            \"    return s\\n\"\n",
    "            \"Кажется, должно работать.\"\n",
    "        ),\n",
    "    ),\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.CHECK_SOLUTION,\n",
    "        content=(\n",
    "            \"Подход корректный для положительных n. Функция вернёт правильную сумму. \"\n",
    "            \"Попробуйте подумать, что будет, если n = 0 или n < 0. \"\n",
    "            \"Как бы вы обработали такие случаи?\"\n",
    "        ),\n",
    "    ),\n",
    "    Message(\n",
    "        role=RoleEnum.USER,\n",
    "        type=TypeEnum.ANSWER,\n",
    "        content=(\n",
    "            \"Можно в начале функции проверить: если n <= 0, то вернуть 0 или, например, \"\n",
    "            \"поднять исключение. Я бы, наверное, вернул 0, чтобы не падать.\"\n",
    "        ),\n",
    "    ),\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.RESPONSE,\n",
    "        content=(\n",
    "            \"Да, проверка в начале — хороший вариант. Для интервью достаточно вернуть 0 и явно это задокументировать. \"\n",
    "            \"По основному случаю решение верное.\"\n",
    "        ),\n",
    "    ),\n",
    "\n",
    "    # 5. Task 2 – FizzBuzz\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.TASK,\n",
    "        content=(\n",
    "            \"[coding][python]\\n\"\n",
    "            \"Задание 2. Реализуйте FizzBuzz: выведите числа от 1 до 100, \"\n",
    "            \"заменяя числа, кратные 3, на 'Fizz', кратные 5 — на 'Buzz', \"\n",
    "            \"а кратные и 3, и 5 — на 'FizzBuzz'. Используйте только базовый Python.\"\n",
    "        ),\n",
    "    ),\n",
    "    Message(\n",
    "        role=RoleEnum.USER,\n",
    "        type=TypeEnum.SOLUTION,\n",
    "        content=(\n",
    "            \"Сделал примерно так:\\n\"\n",
    "            \"for i in range(1, 101):\\n\"\n",
    "            \"    if i % 3 == 0 and i % 5 == 0:\\n\"\n",
    "            \"        print('FizzBuzz')\\n\"\n",
    "            \"    elif i % 3 == 0:\\n\"\n",
    "            \"        print('Fizz')\\n\"\n",
    "            \"    elif i % 5 == 0:\\n\"\n",
    "            \"        print('Buzz')\\n\"\n",
    "            \"    else:\\n\"\n",
    "            \"        print(i)\\n\"\n",
    "        ),\n",
    "    ),\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.CHECK_SOLUTION,\n",
    "        content=(\n",
    "            \"Это классическая и вполне корректная реализация. Логика условий верная, порядок проверок тоже. \"\n",
    "            \"Можно было бы чуть упростить, но для уровня junior такое решение выглядит хорошо.\"\n",
    "        ),\n",
    "    ),\n",
    "\n",
    "    # 6. Небольшой follow-up по коду / читаемости\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.QUESTION,\n",
    "        content=(\n",
    "            \"Как бы вы улучшили читаемость кода в этих задачах? \"\n",
    "            \"Можете привести пример, какие имена переменных или функции вы бы выбрали.\"\n",
    "        ),\n",
    "    ),\n",
    "    Message(\n",
    "        role=RoleEnum.USER,\n",
    "        type=TypeEnum.ANSWER,\n",
    "        content=(\n",
    "            \"Наверное, я бы в FizzBuzz вынес логику в отдельную функцию, например fizzbuzz(n), \"\n",
    "            \"а уже потом вызывал её в цикле. Переменную i можно переименовать в number, чтобы было понятнее. \"\n",
    "            \"В сумме до n можно добавить докстринг к функции.\"\n",
    "        ),\n",
    "    ),\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.RESPONSE,\n",
    "        content=(\n",
    "            \"Отличная идея с вынесением логики в функцию и более говорящими именами. \"\n",
    "            \"Это как раз то, что ожидается от junior-разработчика: рабочий код плюс базовое внимание к читаемости.\"\n",
    "        ),\n",
    "    ),\n",
    "\n",
    "    # 7. Финальное резюме от интервьюера\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.RESPONSE,\n",
    "        content=(\n",
    "            \"На этом мы закончим. В целом вы неплохо справились с практическими задачами: \"\n",
    "            \"код корректный, без лишней сложности. В теории по типам данных есть пробелы \"\n",
    "            \"(особенно по изменяемости строк и кортежей), но это можно подтянуть. \"\n",
    "            \"Спасибо за интервью!\"\n",
    "        ),\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c8c15f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing create_test_suite...\n",
      "=== Running create_test_suite ===\n",
      "\n",
      "=== Test Suite Summary ===\n",
      "Task ID: task_without_id\n",
      "Total tests: 10\n",
      "Visible tests: 4\n",
      "Hidden tests:  6\n",
      "\n",
      "--- Visible tests ---\n",
      "[t1] input='2 7\\n9\\n' -> expected='0 1\\n'\n",
      "[t2] input='3 2 4\\n6\\n' -> expected='1 2\\n'\n",
      "[t3] input='3 3\\n6\\n' -> expected='0 1\\n'\n",
      "[t4] input='1 2 3\\n7\\n' -> expected='-1 -1\\n'\n",
      "\n",
      "--- Hidden tests (ids only) ---\n",
      "[t5] (hidden)\n",
      "[t6] (hidden)\n",
      "[t7] (hidden)\n",
      "[t8] (hidden)\n",
      "[t9] (hidden)\n",
      "[t10] (hidden)\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from datetime import timedelta\n",
    "\n",
    "from src.adapters.ai_chat.ai_chat import AIChat\n",
    "from src.domain.vacancy.vacancy import VacancyInfo\n",
    "from src.domain.message.message import Message, RoleEnum, TypeEnum\n",
    "from src.domain.task.task import Task, TaskType, TaskLanguage\n",
    "from src.domain.test.test import CodeTestSuite, CodeTestCase  # type hints only\n",
    "\n",
    "# ---------- Mock interview plan ----------\n",
    "\n",
    "test_interview_plan = \"\"\"INTERNAL INTERVIEW PLAN ONLY - DO NOT SHARE WITH CANDIDATES\n",
    "\n",
    "1. Разогрев (5 минут)\n",
    "   - [theory] Кратко объяснить, чем список (list) отличается от кортежа (tuple) в Python \n",
    "     и когда что лучше использовать.\n",
    "\n",
    "2. Основная задача (20 минут)\n",
    "   - [coding] Модифицированная задача two-sum без сторонних библиотек:\n",
    "     Дано: список целых чисел nums и целевое число target.\n",
    "     Требуется: найти ДВА индекса i и j (i < j) такие, что nums[i] + nums[j] == target.\n",
    "     Если подходящей пары нет — вернуть -1 -1.\n",
    "\n",
    "3. Wrap-up (5 минут)\n",
    "   - [theory] Попросить кандидата кратко объяснить алгоритм и оценку сложности.\n",
    "\"\"\"\n",
    "\n",
    "# ---------- Vacancy info ----------\n",
    "\n",
    "vacancy_info = VacancyInfo(\n",
    "    profession=\"Python разработчик\",\n",
    "    position=\"Junior Python Developer\",\n",
    "    requirements=\"Уверенное владение Python, базовые алгоритмы и структуры данных, умение писать чистый код.\",\n",
    "    questions=\"Базовые вопросы по Python, списки, кортежи, циклы, функции.\",\n",
    "    tasks=[\n",
    "        \"Разогрев: теоретический вопрос по базовым структурам данных в Python. [theory]\",\n",
    "        \"Основная задача: простая алгоритмическая задача без сторонних библиотек (вариант two-sum). [coding]\",\n",
    "    ],\n",
    "    task_ides=[\"алгоритмическая задача по поиску пары чисел по сумме\"],\n",
    "    interview_plan=test_interview_plan,\n",
    "    duration=timedelta(minutes=30),\n",
    ")\n",
    "\n",
    "# ---------- Chat history (кандидат ответил на теорию, сейчас переходим к коду) ----------\n",
    "\n",
    "ai_welcome_message = (\n",
    "    \"Здравствуйте! Это короткое техническое интервью на позицию Junior Python Developer. \"\n",
    "    \"Сначала обсудим базовую теорию, затем перейдём к одной простой алгоритмической задаче без библиотек. \"\n",
    "    \"Можете задавать уточняющие вопросы по условию, но я не буду писать решение за вас.\"\n",
    ")\n",
    "\n",
    "ai_theory_question = (\n",
    "    \"Первый вопрос: расскажите, чем список (list) отличается от кортежа (tuple) в Python \"\n",
    "    \"и когда вы предпочли бы использовать каждый из них?\"\n",
    ")\n",
    "\n",
    "user_theory_answer = (\n",
    "    \"Список — изменяемый, в него можно добавлять и удалять элементы, \"\n",
    "    \"кортеж — неизменяемый. Списки использую, когда структура данных должна меняться, \"\n",
    "    \"а кортежи — когда важно зафиксировать набор значений, например координаты.\"\n",
    ")\n",
    "\n",
    "ai_theory_feedback_and_move_to_code = (\n",
    "    \"Отличный ответ: вы правильно выделили изменяемость и типичные случаи использования. \"\n",
    "    \"Теперь перейдём к основной задаче по алгоритмам на Python без сторонних библиотек.\"\n",
    ")\n",
    "\n",
    "ai_code_task_intro = (\n",
    "    \"Задача: у вас есть список целых чисел nums и число target. \"\n",
    "    \"Нужно найти ДВА индекса i и j (i < j), такие что nums[i] + nums[j] == target. \"\n",
    "    \"Если подходящей пары нет — верните -1 -1. \"\n",
    "    \"Реализуйте функцию two_sum_modified(nums: list[int], target: int) и выведите индексы через пробел.\"\n",
    ")\n",
    "\n",
    "chat_history = [\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.RESPONSE,\n",
    "        content=ai_welcome_message,\n",
    "    ),\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.QUESTION,\n",
    "        content=ai_theory_question,\n",
    "    ),\n",
    "    Message(\n",
    "        role=RoleEnum.USER,\n",
    "        type=TypeEnum.ANSWER,\n",
    "        content=user_theory_answer,\n",
    "    ),\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.RESPONSE,\n",
    "        content=ai_theory_feedback_and_move_to_code,\n",
    "    ),\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.TASK,\n",
    "        content=ai_code_task_intro,\n",
    "    ),\n",
    "]\n",
    "\n",
    "# ---------- Current coding task object ----------\n",
    "\n",
    "task = Task(\n",
    "    type=TaskType.CODE,\n",
    "    language=TaskLanguage.PYTHON,\n",
    "    description=(\n",
    "        \"Реализуйте функцию two_sum_modified(nums: list[int], target: int), \"\n",
    "        \"которая находит ДВА индекса i и j (i < j), такие что nums[i] + nums[j] == target. \"\n",
    "        \"Если пары нет, выведите \\\"-1 -1\\\". Вход и выход реализуются через stdin/stdout.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# ---------- Candidate solution (plausible correct implementation) ----------\n",
    "\n",
    "candidate_solution_code = \"\"\"\\\n",
    "def two_sum_modified(nums, target):\n",
    "    n = len(nums)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if nums[i] + nums[j] == target:\n",
    "                print(i, j)\n",
    "                return\n",
    "    print(-1, -1)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    data = sys.stdin.read().strip().split()\n",
    "    if not data:\n",
    "        print(\"-1 -1\")\n",
    "    else:\n",
    "        *nums_str, target_str = data\n",
    "        nums = [int(x) for x in nums_str]\n",
    "        target = int(target_str)\n",
    "        two_sum_modified(nums, target)\n",
    "\"\"\"\n",
    "\n",
    "ai_chat = AIChat()\n",
    "\n",
    "# ---------- Test for create_test_suite ----------\n",
    "\n",
    "async def test_create_test_suite() -> CodeTestSuite:\n",
    "    ai_chat_local = AIChat()\n",
    "\n",
    "    print(\"=== Running create_test_suite ===\\n\")\n",
    "\n",
    "    suite = await ai_chat_local.create_test_suite(\n",
    "        vacancy_info=vacancy_info,\n",
    "        chat_history=chat_history,\n",
    "        task=task,\n",
    "    )\n",
    "\n",
    "    print(\"=== Test Suite Summary ===\")\n",
    "    print(f\"Task ID: {suite.task_id}\")\n",
    "    print(f\"Total tests: {len(suite.tests)}\")\n",
    "\n",
    "    visible = [t for t in suite.tests if not t.is_hidden]\n",
    "    hidden = [t for t in suite.tests if t.is_hidden]\n",
    "\n",
    "    print(f\"Visible tests: {len(visible)}\")\n",
    "    print(f\"Hidden tests:  {len(hidden)}\\n\")\n",
    "\n",
    "    print(\"--- Visible tests ---\")\n",
    "    for t in visible:\n",
    "        print(f\"[{t.id}] input={repr(t.input_data)} -> expected={repr(t.expected_output)}\")\n",
    "\n",
    "    print(\"\\n--- Hidden tests (ids only) ---\")\n",
    "    for t in hidden:\n",
    "        print(f\"[{t.id}] (hidden)\")\n",
    "\n",
    "    return suite\n",
    "\n",
    "# ---------- Test for check_solution, reusing the created suite ----------\n",
    "\n",
    "async def test_check_solution(suite: CodeTestSuite) -> None:\n",
    "    ai_chat_local = AIChat()\n",
    "\n",
    "    # Imitate that the external runner already executed tests and filled correctness flags.\n",
    "    # Here we assume the candidate solution performed well: almost all tests passed.\n",
    "    if suite.tests:\n",
    "        # Mark all as passed by default\n",
    "        for t in suite.tests:\n",
    "            t.correct = True\n",
    "\n",
    "        # Optionally, make one hidden test fail to simulate a subtle bug:\n",
    "        # if len(suite.tests) > 2:\n",
    "        #     suite.tests[-1].correct = False\n",
    "\n",
    "    # Extend chat history with a short user message like \"please check my solution\"\n",
    "    chat_with_solution_request = chat_history + [\n",
    "        Message(\n",
    "            role=RoleEnum.USER,\n",
    "            type=TypeEnum.SOLUTION,\n",
    "            content=\"Я написал решение в редакторе, пожалуйста, проверьте его на тестах.\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    print(\"\\n=== Running check_solution ===\\n\")\n",
    "\n",
    "    stream, ai_msg = await ai_chat_local.check_solution(\n",
    "        vacancy_info=vacancy_info,\n",
    "        chat_history=chat_with_solution_request,\n",
    "        task=task,\n",
    "        solution=candidate_solution_code,\n",
    "        tests=suite,\n",
    "    )\n",
    "\n",
    "    chunks: list[str] = []\n",
    "    async for chunk in stream:\n",
    "        chunks.append(chunk)\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "\n",
    "    ai_msg.content = \"\".join(chunks)\n",
    "\n",
    "    print(\"\\n\\n=== Final check_solution message ===\")\n",
    "    print(f\"Role: {ai_msg.role}\")\n",
    "    print(f\"Type: {ai_msg.type}\")\n",
    "    print(f\"Content:\\n{ai_msg.content}\")\n",
    "\n",
    "\n",
    "# ---------- Run tests ----------\n",
    "\n",
    "print(\"Testing create_test_suite...\")\n",
    "suite = await test_create_test_suite()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4927a5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing check_solution...\n",
      "\n",
      "=== Running check_solution ===\n",
      "\n",
      "\n",
      "\n",
      "Ваше решение прошло 4 из 10 видимых тестов, но не сдало скрытые проверки. Например, для входа `-1 0` и `target=-1` алгоритм возвращает правильный ответ `0 1`, но возможно есть ошибки в обработке дубликатов или сложных комбинаций. Рассмотрите оптимизацию через хэш-таблицу (словарь) для хранения значений и их индексов — это сократит сложность с O(n²) до O(n). Проверьте также, возвращается ли всегда первая подходящая пара, а не любая.\n",
      "\n",
      "=== Final check_solution message ===\n",
      "Role: ai\n",
      "Type: check_solution\n",
      "Content:\n",
      "\n",
      "\n",
      "Ваше решение прошло 4 из 10 видимых тестов, но не сдало скрытые проверки. Например, для входа `-1 0` и `target=-1` алгоритм возвращает правильный ответ `0 1`, но возможно есть ошибки в обработке дубликатов или сложных комбинаций. Рассмотрите оптимизацию через хэш-таблицу (словарь) для хранения значений и их индексов — это сократит сложность с O(n²) до O(n). Проверьте также, возвращается ли всегда первая подходящая пара, а не любая.\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing check_solution...\")\n",
    "await test_check_solution(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58ce50f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing generate_welcome_message...\n",
      "\n",
      "=== Welcome Message (streaming) ===\n",
      "\n",
      "\n",
      "\n",
      "Добро пожаловать на техническое интервью! В ходе следующих 30 минут вы решите одну-две задачи на Python, а мы обсудим ваши подходы и код. Задачи будут проверять знание базовых структур данных, алгоритмов и практик работы с Python. Время ограничено, поэтому старайтесь быть эффективными. \n",
      "\n",
      "Важно: \n",
      "- Все решения нужно писать самостоятельно, без использования внешних инструментов (LLM, сторонние библиотеки и т.п.).\n",
      "- Копирование кода извне или попытки обойти правила приведут к дискаualификации.\n",
      "- Вы можете задавать уточняющие вопросы по условию, но я не буду писать готовые решения.\n",
      "\n",
      "Первая задача будет отправлена через несколько секунд. Удачи!\n",
      "\n",
      "=== Full Welcome Message ===\n",
      "\n",
      "\n",
      "Добро пожаловать на техническое интервью! В ходе следующих 30 минут вы решите одну-две задачи на Python, а мы обсудим ваши подходы и код. Задачи будут проверять знание базовых структур данных, алгоритмов и практик работы с Python. Время ограничено, поэтому старайтесь быть эффективными. \n",
      "\n",
      "Важно: \n",
      "- Все решения нужно писать самостоятельно, без использования внешних инструментов (LLM, сторонние библиотеки и т.п.).\n",
      "- Копирование кода извне или попытки обойти правила приведут к дискаualификации.\n",
      "- Вы можете задавать уточняющие вопросы по условию, но я не буду писать готовые решения.\n",
      "\n",
      "Первая задача будет отправлена через несколько секунд. Удачи!\n"
     ]
    }
   ],
   "source": [
    "async def test_generate_welcome_message():\n",
    "    ai_chat = AIChat()\n",
    "    \n",
    "    # First create chat to get updated vacancy with interview_plan\n",
    "    # updated_vacancy = await ai_chat.create_chat(vacancy_info, chat_history)\n",
    "    updated_vacancy = vacancy_info\n",
    "    print(\"\\n=== Welcome Message (streaming) ===\\n\")\n",
    "    welcome_chunks = []\n",
    "    \n",
    "    # ❌ before:\n",
    "    # async for chunk in ai_chat.generate_welcome_message(updated_vacancy, chat_history):\n",
    "\n",
    "    # ✅ after:\n",
    "    stream = await ai_chat.generate_welcome_message(updated_vacancy, chat_history)\n",
    "    async for chunk in stream:\n",
    "        welcome_chunks.append(chunk)\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "    \n",
    "    print(\"\\n\\n=== Full Welcome Message ===\")\n",
    "    full_welcome = \"\".join(welcome_chunks)\n",
    "    print(full_welcome)\n",
    "    \n",
    "print(\"Testing generate_welcome_message...\")\n",
    "await test_generate_welcome_message()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5fce45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\Dev\\\\interview-service\\\\interview-service'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "722724bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing create_metrics...\n",
      "=== Running create_metrics ===\n",
      "\n",
      "=== MetricsBlock1 (input) ===\n",
      "time_spent:        0:29:00\n",
      "time_per_task:     0:07:00\n",
      "answers_count:     10\n",
      "copy_paste_suspicion: 1\n",
      "\n",
      "=== MetricsBlock2 (LLM) ===\n",
      "summary:\n",
      "Кандидат показал базовое понимание Python, особенно в практической реализации задач (sum_to_n и FizzBuzz). В теоретических вопросах имелись неточности по изменяемости строк и кортежей, но он улучшил ответы после подсказок. В задачах учитывал граничные случаи и предлагал улучшения читаемости кода. Коммуникация была понятной, хотя в начальных вопросах были сомнения.\n",
      "\n",
      "clarity_score:      3\n",
      "completeness_score: 4\n",
      "feedback_response:  Кандидат активно реагировал на подсказки: исправил ошибки в понимании изменяемости строк и добавил обработку граничных случаев в функцию sum_to_n. Это показывает способность принимать обратную связь и адаптироваться.\n",
      "tech_fit_level:     medium\n",
      "tech_fit_comment:   Кандидат справился с базовыми задачами на циклы и условия, реализовал корректный FizzBuzz и улучшил код после подсказок. Однако в теории по типам данных были пробелы (например, не сразу понял неизменяемость строк), что характерно для junior-уровня. Уровень технической подготовки соответствует требованиям вакансии, но требует дополнительной доработки в теоретических аспектах.\n",
      "\n",
      "=== MetricsBlock3 (LLM) ===\n",
      "strengths:\n",
      "Кандидат показал умение решать практические задачи на циклы и условия, корректно реализовал функции sum_to_n и FizzBuzz. Успешно адаптировался к подсказкам, добавив обработку граничных случаев и предложения по улучшению читаемости кода. Демонстрировал понимание базовой структуры кода и готовность улучшать его читаемость через более говорящие имена и модульность.\n",
      "\n",
      "weaknesses:\n",
      "Имел пробелы в теоретических знаниях по изменяемости объектов: изначально не сразу понял неизменяемость строк и кортежей. В начальных вопросах о разнице между списками, кортежами и строками отвечал неточно, хотя улучшил ответы после подсказок. Это указывает на необходимость углубления в фундаментальные концепции Python.\n",
      "\n",
      "cheating_summary:\n",
      "Нет явных признаков читерства. Код был написан вручную, ответы соответствовали задачам, а сигнал copy_paste_suspicion равен 1 (минимальный уровень подозрений).\n",
      "\n",
      "seniority_guess: junior\n",
      "recommendation:  hire\n"
     ]
    }
   ],
   "source": [
    "# from datetime import timedelta\n",
    "# from src.domain.metrics.metrics import MetricsBlock1\n",
    "# from src.adapters.ai_chat.ai_chat import AIChat\n",
    "\n",
    "# Mock MetricsBlock1 for a ~30-minute interview\n",
    "metrics_block1 = MetricsBlock1(\n",
    "    time_spent=timedelta(minutes=29),\n",
    "    time_per_task=timedelta(minutes=7),  # e.g. 4 tasks roughly\n",
    "    answers_count=10,\n",
    "    copy_paste_suspicion=1,  # low suspicion\n",
    ")\n",
    "\n",
    "# Test create_metrics function\n",
    "async def test_create_metrics():\n",
    "    ai_chat = AIChat()\n",
    "\n",
    "    print(\"=== Running create_metrics ===\\n\")\n",
    "\n",
    "    block1, block2, block3 = await ai_chat.create_metrics(\n",
    "        vacancy_info=vacancy_info,\n",
    "        chat_history=chat_history,\n",
    "        metrics_block1=metrics_block1,\n",
    "    )\n",
    "\n",
    "    # ---- Block 1 (input, just to confirm) ----\n",
    "    print(\"=== MetricsBlock1 (input) ===\")\n",
    "    print(f\"time_spent:        {block1.time_spent}\")\n",
    "    print(f\"time_per_task:     {block1.time_per_task}\")\n",
    "    print(f\"answers_count:     {block1.answers_count}\")\n",
    "    print(f\"copy_paste_suspicion: {block1.copy_paste_suspicion}\")\n",
    "    print()\n",
    "\n",
    "    # ---- Block 2 (LLM-generated) ----\n",
    "    print(\"=== MetricsBlock2 (LLM) ===\")\n",
    "    print(f\"summary:\\n{block2.summary}\\n\")\n",
    "    print(f\"clarity_score:      {block2.clarity_score}\")\n",
    "    print(f\"completeness_score: {block2.completeness_score}\")\n",
    "    print(f\"feedback_response:  {block2.feedback_response}\")\n",
    "    print(f\"tech_fit_level:     {block2.tech_fit_level.value}\")\n",
    "    print(f\"tech_fit_comment:   {block2.tech_fit_comment}\")\n",
    "    print()\n",
    "\n",
    "    # ---- Block 3 (LLM-generated) ----\n",
    "    print(\"=== MetricsBlock3 (LLM) ===\")\n",
    "    print(f\"strengths:\\n{block3.strengths}\\n\")\n",
    "    print(f\"weaknesses:\\n{block3.weaknesses}\\n\")\n",
    "    print(f\"cheating_summary:\\n{block3.cheating_summary}\\n\")\n",
    "    print(f\"seniority_guess: {block3.seniority_guess.value}\")\n",
    "    print(f\"recommendation:  {block3.recommendation.value}\")\n",
    "    \n",
    "    return block1, block2, block3\n",
    "\n",
    "\n",
    "print(\"Testing create_metrics...\")\n",
    "block1, block2, block3 = await test_create_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c4145b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat history where the candidate has already answered\n",
    "# the warm-up + all theoretical questions.\n",
    "# The last message is the candidate's answer about TensorFlow vs PyTorch,\n",
    "# so the next step according to the plan should be Core Coding Task 1.\n",
    "\n",
    "chat_history = [\n",
    "    # Greeting / intro\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.RESPONSE,\n",
    "        content=ai_message_content_1,\n",
    "    ),\n",
    "\n",
    "    # Warm-up question: Pandas vs NumPy\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.QUESTION,\n",
    "        content=(\n",
    "            \"Поясните основные случаи использования Pandas DataFrames и NumPy ndarrays. \"\n",
    "            \"В каких ситуациях вы выберете один инструмент вместо другого?\"\n",
    "        ),\n",
    "    ),\n",
    "    Message(\n",
    "        role=RoleEnum.USER,\n",
    "        type=TypeEnum.ANSWER,\n",
    "        content=(\n",
    "            \"Pandas DataFrame я бы использовал для работы с табличными данными — когда есть \"\n",
    "            \"строки и столбцы, фильтрация, группировки, агрегации, merge/join. \"\n",
    "            \"NumPy ndarray — когда нужны векторизованные численные вычисления, линейная алгебра, \"\n",
    "            \"работа с многомерными массивами и матрицами. Обычно я загружаю данные в DataFrame, \"\n",
    "            \"а при необходимости могу вытащить values в ndarray для матричных операций.\"\n",
    "        ),\n",
    "    ),\n",
    "\n",
    "    # Короткий фидбек по первому вопросу\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.CHECK_SOLUTION,\n",
    "        content=(\n",
    "            \"Хорошо, вы верно разделили области применения: Pandas для табличных операций и \"\n",
    "            \"анализa данных, NumPy для низкоуровневых численных вычислений и линейной алгебры. \"\n",
    "            \"Перейдём к следующим теоретическим вопросам.\"\n",
    "        ),\n",
    "    ),\n",
    "\n",
    "    # Теоретический вопрос 1: SQLAlchemy ORM\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.QUESTION,\n",
    "        content=(\n",
    "            \"Расскажите, для чего нужен ORM-слой в SQLAlchemy и чем работа через ORM удобнее, \"\n",
    "            \"чем использование сырых SQL-запросов?\"\n",
    "        ),\n",
    "    ),\n",
    "    Message(\n",
    "        role=RoleEnum.USER,\n",
    "        type=TypeEnum.ANSWER,\n",
    "        content=(\n",
    "            \"ORM в SQLAlchemy позволяет описывать таблицы как Python-классы и работать с ними \"\n",
    "            \"как с объектами. Вместо ручной сборки SQL-запросов я пишу выражения на Python, а \"\n",
    "            \"SQLAlchemy генерирует SQL под конкретную СУБД. Это снижает количество шаблонного кода, \"\n",
    "            \"даёт типизацию на уровне моделей и упрощает миграции между базами. При этом при \"\n",
    "            \"необходимости можно всегда написать raw SQL.\"\n",
    "        ),\n",
    "    ),\n",
    "\n",
    "    # Короткий фидбек по SQLAlchemy-вопросу\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.CHECK_SOLUTION,\n",
    "        content=(\n",
    "            \"Да, верно: ORM абстрагирует SQL, позволяет работать с моделями, а не строками запросов, \"\n",
    "            \"и упрощает переносимость и сопровождение кода. Теперь последний теоретический вопрос.\"\n",
    "        ),\n",
    "    ),\n",
    "\n",
    "    # Теоретический вопрос 2: TensorFlow vs PyTorch\n",
    "    Message(\n",
    "        role=RoleEnum.AI,\n",
    "        type=TypeEnum.QUESTION,\n",
    "        content=(\n",
    "            \"Сравните TensorFlow и PyTorch. В каких сценариях обычно используют каждый из этих \"\n",
    "            \"фреймворков и чем они отличаются с точки зрения разработки?\"\n",
    "        ),\n",
    "    ),\n",
    "\n",
    "    # Последнее сообщение — ответ кандидата.\n",
    "    # После этого create_task должен взять Task 1 из секции Core Coding Tasks.\n",
    "    Message(\n",
    "        role=RoleEnum.USER,\n",
    "        type=TypeEnum.ANSWER,\n",
    "        content=(\n",
    "            \"PyTorch чаще используют для научных исследований и прототипирования, потому что у него \"\n",
    "            \"динамический вычислительный граф и более 'питоничный' стиль кода — удобно дебажить и \"\n",
    "            \"экспериментировать. TensorFlow больше ориентирован на продакшен и развёртывание: там есть \"\n",
    "            \"TensorFlow Serving, TFLite, хорошая интеграция с экосистемой Google. Сейчас границы \"\n",
    "            \"размылись, но в целом: PyTorch — быстрее стартовать и iterировать модель, TensorFlow — \"\n",
    "            \"удобнее, когда нужно выстроить целую продакшен-пайплайн.\"\n",
    "        ),\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0a4e209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing create_response...\n",
      "=== Classification ===\n",
      "User message type:      question\n",
      "Assistant message type: hint\n",
      "\n",
      "=== AI response (streaming) ===\n",
      "\n",
      "  \n",
      "NumPy ndarray (N-мерный массив) — это основной тип данных в NumPy для работы с числовыми данными, оптимизированный для высокой производительности. Он представляет собой однородную структуру (все элементы одного типа) и поддерживает векторизованные операции. Pandas DataFrame — это структура, похожая на таблицу в Excel, с поддержкой разнотиповых колонок, индексации и операций, характерных для работы с данными (фильтрация, группировка и т.д.).  \n",
      "\n",
      "Попробуйте сформулировать, в каких сценариях использование одного из этих инструментов предпочтительнее. Например: когда нужно выполнять математические вычисления над массивами данных — NumPy, а когда работать с табличными данными, содержащими разнородные типы — Pandas.\n",
      "\n",
      "=== Final AI message ===\n",
      "Role:    ai\n",
      "Type:    hint\n",
      "Content:   \n",
      "NumPy ndarray (N-мерный массив) — это основной тип данных в NumPy для работы с числовыми данными, оптимизированный для высокой производительности. Он представляет собой однородную структуру (все элементы одного типа) и поддерживает векторизованные операции. Pandas DataFrame — это структура, похожая на таблицу в Excel, с поддержкой разнотиповых колонок, индексации и операций, характерных для работы с данными (фильтрация, группировка и т.д.).  \n",
      "\n",
      "Попробуйте сформулировать, в каких сценариях использование одного из этих инструментов предпочтительнее. Например: когда нужно выполнять математические вычисления над массивами данных — NumPy, а когда работать с табличными данными, содержащими разнородные типы — Pandas.\n"
     ]
    }
   ],
   "source": [
    "# Test create_response function\n",
    "async def test_create_response():\n",
    "    ai_chat = AIChat()\n",
    "    \n",
    "    # Example task for this interview turn\n",
    "    task = Task(\n",
    "        type=TaskType.THEORY,\n",
    "        language=\"Python\",\n",
    "        description=\"Поясните основные случаи использования Pandas DataFrames и NumPy ndarrays. В каких ситуациях вы выберете один инструмент вместо другого?\"\n",
    "    )\n",
    "\n",
    "    stream, user_msg, ai_msg = await ai_chat.create_response(\n",
    "        vacancy_info=vacancy_info,\n",
    "        chat_history=chat_history,\n",
    "        task=task,\n",
    "    )\n",
    "\n",
    "    # Fill user message content from the last USER message in history\n",
    "    last_user_msg = next((m for m in reversed(chat_history) if m.role == RoleEnum.USER), None)\n",
    "    if last_user_msg:\n",
    "        user_msg.content = last_user_msg.content\n",
    "\n",
    "    print(\"=== Classification ===\")\n",
    "    print(f\"User message type:      {user_msg.type}\")\n",
    "    print(f\"Assistant message type: {ai_msg.type}\")\n",
    "\n",
    "    print(\"\\n=== AI response (streaming) ===\\n\")\n",
    "    chunks: list[str] = []\n",
    "    async for chunk in stream:\n",
    "        chunks.append(chunk)\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "\n",
    "    ai_msg.content = \"\".join(chunks)\n",
    "\n",
    "    print(\"\\n\\n=== Final AI message ===\")\n",
    "    print(f\"Role:    {ai_msg.role}\")\n",
    "    print(f\"Type:    {ai_msg.type}\")\n",
    "    print(f\"Content: {ai_msg.content}\")\n",
    "\n",
    "\n",
    "print(\"Testing create_response...\")\n",
    "await test_create_response()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4964646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing create_task...\n",
      "=== Task metadata from <ctrl> ===\n",
      "Task type:      TaskType.CODE\n",
      "Task language:  TaskLanguage.PYTHON\n",
      "\n",
      "=== Task description (streaming) ===\n",
      "\n",
      "\n",
      "Напишите код на Pandas для загрузки CSV-файла из стандартного ввода, фильтрации строк, где значение в колонке 'A' превышает 10, и вычисления среднего значения колонки 'B' среди оставшихся строк. Результат выведите в стандартный вывод. Учтите, что файл содержит заголовок с именами колонок.\n",
      "\n",
      "=== Final Task object ===\n",
      "Task type:      TaskType.CODE\n",
      "Task language:  TaskLanguage.PYTHON\n",
      "Description:\n",
      "\n",
      "Напишите код на Pandas для загрузки CSV-файла из стандартного ввода, фильтрации строк, где значение в колонке 'A' превышает 10, и вычисления среднего значения колонки 'B' среди оставшихся строк. Результат выведите в стандартный вывод. Учтите, что файл содержит заголовок с именами колонок.\n"
     ]
    }
   ],
   "source": [
    "# Test create_task function\n",
    "async def test_create_task():\n",
    "    ai_chat = AIChat()\n",
    "\n",
    "    # Ask AI to generate the next task\n",
    "    stream, task = await ai_chat.create_task(\n",
    "        vacancy_info=vacancy_info,\n",
    "        chat_history=chat_history,\n",
    "    )\n",
    "\n",
    "    print(\"=== Task metadata from <ctrl> ===\")\n",
    "    print(f\"Task type:      {task.type}\")\n",
    "    print(f\"Task language:  {task.language}\")\n",
    "\n",
    "    print(\"\\n=== Task description (streaming) ===\\n\")\n",
    "    chunks: list[str] = []\n",
    "    async for chunk in stream:\n",
    "        chunks.append(chunk)\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "\n",
    "    # Store full description back into the Task object\n",
    "    task.description = \"\".join(chunks)\n",
    "\n",
    "    print(\"\\n\\n=== Final Task object ===\")\n",
    "    print(f\"Task type:      {task.type}\")\n",
    "    print(f\"Task language:  {task.language}\")\n",
    "    print(f\"Description:\\n{task.description}\")\n",
    "\n",
    "    # So you can use it later in the notebook/code\n",
    "    return task\n",
    "\n",
    "\n",
    "print(\"Testing create_task...\")\n",
    "generated_task = await test_create_task()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dc572ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stream' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mstream\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'stream' is not defined"
     ]
    }
   ],
   "source": [
    "stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ee1d46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing create_chat...\n",
      "=== Updated Vacancy Info ===\n",
      "Profession: Python разработчик / Data Scientist\n",
      "Position: Junior Python Developer\n",
      "\n",
      "Interview Plan (first 300 chars):\n",
      "INTERNAL INTERVIEW PLAN ONLY (DO NOT SHARE WITH CANDIDATE)\n",
      "\n",
      "1. **Warm-up (5-10 min)**  \n",
      "   - [theory] Explain how to handle missing data in Pandas DataFrames. Demonstrate .dropna() vs .fillna() with example scenarios.  \n",
      "\n",
      "2. **Core Libraries Assessment (30-40 min)**  \n",
      "   - [coding] Numpy task: Write a function to normalize a 2D array (row-wise) and handle division by zero.  \n",
      "   - [theory] Compare Tensorflow and PyTorch: When would you choose one over the other? Discuss dynamic vs static computation graphs.  \n",
      "\n",
      "3. **ML Frameworks Practical (20-30 min)**  \n",
      "   - [coding] PyTorch task: Implement a single-layer neural network for binary classification (define model, loss function, and optimizer).  \n",
      "\n",
      "4. **Database Integration (15-20 min)**  \n",
      "   - [theory] Explain SQLAlchemy's ORM approach. How does it differ from raw SQL? Provide an example of a mapped class for a \"users\" table.  \n",
      "\n",
      "5. **Wrap-up (5 min)**  \n",
      "   - Open chat discussion: Ask candidate to explain their most complex Python project and challenges with data manipulation/ML pipeline.  \n",
      "\n",
      "Note: Prioritize coding tasks for Numpy/PyTorch, ensure theoretical questions validate understanding of core concepts. Adjust timing based on candidate pace....\n",
      "\n",
      "Full Interview Plan Length: 1209 characters\n",
      "\n",
      "==================================================\n",
      "\n",
      "Testing generate_welcome_message...\n",
      "\n",
      "=== Welcome Message (streaming) ===\n",
      "\n",
      "Thinking...\n",
      "Finished thinking.\n",
      "\n",
      "\n",
      "Здравствуйте! Добро пожаловать на техническое интервью.  \n",
      "В ходе интервью вы будете решать задачи на Python (Pandas, Numpy, PyTorch и др.) в встроенной среде. Время ограничено, поэтому работайте аккуратно и оперативно.  \n",
      "Вы можете задавать уточняющие вопросы по условию задач, но не ожидайте, что я напишу решение за вас — я помогу направить вас в правильное русло. Мы также обсудим ваш подход и код.  \n",
      "**Важно:** не используйте внешние инструменты (LLM, поисковики), не копируйте код извне — всё должно быть введено вручную. Попытки обойти правила приведут к дезавалидации интервью.  \n",
      "Чат будет проверен после завершения. Начнём с первой задачи — готовы?\n",
      "\n",
      "=== Full Welcome Message ===\n",
      "Thinking...\n",
      "Finished thinking.\n",
      "\n",
      "\n",
      "Здравствуйте! Добро пожаловать на техническое интервью.  \n",
      "В ходе интервью вы будете решать задачи на Python (Pandas, Numpy, PyTorch и др.) в встроенной среде. Время ограничено, поэтому работайте аккуратно и оперативно.  \n",
      "Вы можете задавать уточняющие вопросы по условию задач, но не ожидайте, что я напишу решение за вас — я помогу направить вас в правильное русло. Мы также обсудим ваш подход и код.  \n",
      "**Важно:** не используйте внешние инструменты (LLM, поисковики), не копируйте код извне — всё должно быть введено вручную. Попытки обойти правила приведут к дезавалидации интервью.  \n",
      "Чат будет проверен после завершения. Начнём с первой задачи — готовы?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test create_chat function\n",
    "async def test_create_chat():\n",
    "    ai_chat = AIChat()\n",
    "    \n",
    "    # create_chat returns updated VacancyInfo with interview_plan\n",
    "    updated_vacancy = await ai_chat.create_chat(vacancy_info, chat_history)\n",
    "    \n",
    "    print(\"=== Updated Vacancy Info ===\")\n",
    "    print(f\"Profession: {updated_vacancy.profession}\")\n",
    "    print(f\"Position: {updated_vacancy.position}\")\n",
    "    print(f\"\\nInterview Plan (first 300 chars):\")\n",
    "    print(updated_vacancy.interview_plan + \"...\" if len(updated_vacancy.interview_plan) > 300 else updated_vacancy.interview_plan)\n",
    "    print(f\"\\nFull Interview Plan Length: {len(updated_vacancy.interview_plan)} characters\")\n",
    "\n",
    "# Test generate_welcome_message function\n",
    "async def test_generate_welcome_message():\n",
    "    ai_chat = AIChat()\n",
    "    \n",
    "    # First create chat to get updated vacancy with interview_plan\n",
    "    updated_vacancy = await ai_chat.create_chat(vacancy_info, chat_history)\n",
    "    \n",
    "    print(\"\\n=== Welcome Message (streaming) ===\\n\")\n",
    "    welcome_chunks = []\n",
    "    \n",
    "    # ❌ before:\n",
    "    # async for chunk in ai_chat.generate_welcome_message(updated_vacancy, chat_history):\n",
    "\n",
    "    # ✅ after:\n",
    "    stream = await ai_chat.generate_welcome_message(updated_vacancy, chat_history)\n",
    "    async for chunk in stream:\n",
    "        welcome_chunks.append(chunk)\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "    \n",
    "    print(\"\\n\\n=== Full Welcome Message ===\")\n",
    "    full_welcome = \"\".join(welcome_chunks)\n",
    "    print(full_welcome)\n",
    "\n",
    "# Run the async functions\n",
    "print(\"Testing create_chat...\")\n",
    "await test_create_chat()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Testing generate_welcome_message...\")\n",
    "await test_generate_welcome_message()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a2453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test create_response function (for reference)\n",
    "async def test_create_response():\n",
    "    ai_chat = AIChat()\n",
    "    \n",
    "    # First create chat to get updated vacancy\n",
    "    updated_vacancy = await ai_chat.create_chat(vacancy_info, chat_history)\n",
    "    \n",
    "    # Then create response with task\n",
    "    print(\"\\n=== Response to Task (streaming) ===\\n\")\n",
    "    response_chunks = []\n",
    "    stream = await ai_chat.create_response(updated_vacancy, chat_history, task)\n",
    "    async for chunk in stream:\n",
    "        response_chunks.append(chunk)\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "    \n",
    "    print(\"\\n\\n=== Full Response ===\")\n",
    "    full_response = \"\".join(response_chunks)\n",
    "    print(full_response)\n",
    "\n",
    "# Run the async function\n",
    "await test_create_response()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dfee1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fee9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERNAL INTERVIEW PLAN ONLY - DO NOT SHARE WITH CANDIDATES  \n",
      "\n",
      "1. **Warm-up Question (5-7 min)**  \n",
      "   - [theory] *Explain the primary use cases for Pandas DataFrames vs. NumPy ndarrays. When would you choose one over the other?*  \n",
      "\n",
      "2. **Theoretical Questions (10-12 min)**  \n",
      "   - [theory] *What is the purpose of SQLAlchemy's ORM layer? How does it simplify database interactions compared to raw SQL?*  \n",
      "   - [theory] *Compare TensorFlow and PyTorch. In what scenarios is each framework typically preferred?*  \n",
      "\n",
      "3. **Core Coding Tasks (30-35 min)**  \n",
      "   - **Task 1** [coding] *Write Pandas code to load a CSV file, filter rows where column 'A' > 10, and calculate the mean of column 'B'.*  \n",
      "   - **Task 2** [coding] *Create a NumPy array of shape (3,3) filled with random values. Compute eigenvalues and perform matrix inversion.*  \n",
      "   - **Task 3** [coding] *Build a simple neural network (1 hidden layer) using PyTorch/TensorFlow to classify the Iris dataset (skeleton code provided). Compile and explain the model.*  \n",
      "\n",
      "4. **Follow-up & Debugging (10-12 min)**  \n",
      "   - [theory] *Explain how you would optimize the Pandas code for large datasets.*  \n",
      "   - [coding] *Debug a provided SQLAlchemy ORM query that fails to join two tables correctly.*  \n",
      "\n",
      "5. **Wrap-up (3-5 min)**  \n",
      "   - [theory] *What are the key challenges when integrating NumPy/TensorFlow for GPU-accelerated computations?*  \n",
      "\n",
      "---  \n",
      "**Timing Notes**: Adjust based on candidate performance. Prioritize depth in core libraries (Pandas, NumPy) over framework specifics.\n",
      "\n",
      "=== Streaming Task Description ===\n",
      "\n",
      "Thinking...\n",
      "Finished thinking.\n",
      "\n",
      "\n",
      "[theory]  \n",
      "Поясните основные случаи использования Pandas DataFrames и NumPy ndarrays. В каких ситуациях вы выберете один инструмент вместо другого?\n",
      "\n",
      "=== Full Task Description ===\n",
      "Thinking...\n",
      "Finished thinking.\n",
      "\n",
      "\n",
      "[theory]  \n",
      "Поясните основные случаи использования Pandas DataFrames и NumPy ndarrays. В каких ситуациях вы выберете один инструмент вместо другого?\n"
     ]
    }
   ],
   "source": [
    "# Test stream_task function\n",
    "async def test_stream_task():\n",
    "    ai_chat = AIChat()\n",
    "    \n",
    "    # First create chat to get updated vacancy with interview_plan\n",
    "    # updated_vacancy = await ai_chat.create_chat(vacancy_info, chat_history)\n",
    "    vacancy_info.interview_plan = test_interview_plan\n",
    "    updated_vacancy = vacancy_info\n",
    "    print(updated_vacancy.interview_plan)\n",
    "    # Then stream the task\n",
    "    print(\"\\n=== Streaming Task Description ===\\n\")\n",
    "    task_chunks = []\n",
    "    \n",
    "    stream = await ai_chat.stream_task(updated_vacancy, chat_history)\n",
    "    async for chunk in stream:\n",
    "        task_chunks.append(chunk)\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "    \n",
    "    print(\"\\n\\n=== Full Task Description ===\")\n",
    "    full_task = \"\".join(task_chunks)\n",
    "    print(full_task)\n",
    "\n",
    "# Run the async function\n",
    "await test_stream_task()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
